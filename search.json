[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Final Project/project post.html",
    "href": "posts/Final Project/project post.html",
    "title": "Final Group Project",
    "section": "",
    "text": "Link to our group github repository : https://github.com/Coding-Tom-1405/PIC16B-Group-Project\n\n\nThe project is about making a memory game that measures people’s short-term memory and helps remembering things better. The game provides users with randomly arranged numbers. After a certain amount of time, the numbers disappear, then users have to remember where each number was and click boxes in the correct order. We made this game using Pygame that allows us to make cool games.\nWe didn’t just make the game. We also created a website where players could choose some potions of the game and see how well they were doing with visualization. For the website, we used Flask, which allows to create a website in Python. After players play the game, users can move to a stats page and see charts and statistics about the game. We used library called Plotly to make these charts.\nBelow is a simple flow chart how our projet works and data is handled.\n\n\n\nFlow Chart\n\n\n\n\n\nThe pygame portion of your project serves as the core gameplay engine for the memory game. This game, inspired by the “chimp test,” challenges players to remember and select squares in the order of their numbers, which are initially displayed and then hidden.\nThe difficulty adjustment and going to the next level are one of the main features of the game. The difficulty affects the number of squares that appear as the player progresses, making the game even more difficult. This adjustment is made possible through the difficulty variable, which is read from a csv file and affects the number of squares that are generated at each new level.\n\n# Taking into account user's difficulty and/or challenge chosen                 \nwith open(\"game_setting.csv\", 'r') as file:                    \n    last_line = file.readlines()[-1]                        # Accessing the last entry row\n    difficulty = int(last_line.split(',')[0])               \n                                                            # Taking the 1st integer variable as difficulty\n    if last_line.split(',')[1] == 'timer\\n' :               # Checking if 2nd element says timer chosen\n        timer_chosen = 1\n    else :                                                  \n        timer_chosen = 0\n        \n\n# Winning Condition and Level Progression\nif len(num_list) == len(square_group):        # Checking if all squares were clicked\n    win = num_list == [str(squares.number) for squares in square_group] # Setting win condition\n    \n    if win:\n        reset_coord()                         \n        num_list = []\n        for i in range(difficulty):           # Adding number of squares equal to difficulty chosen\n            square_group.add(Square(len(square_group) + 1, make_square=False)) \nThe latter part of the code explains about the winning condition, This section checks if the player has clicked all the squares (len(num_list) == len(square_group)), num_list tracks the squares the player has clicked in order.\nThe win condition checks if the sequence of squares clicked by the player (num_list) matches the intended sequence, which is determined by the order of numbers assigned to each square in square_group.\nWhen the win condition meets, the game resets the coordinates for the squares (reset_coord()), clears the num_list, and adds new squares according to the difficulty level. The number of squares increases depending on the level of difficulty chosen.\n\n\n\nGame WIndow\n\n\nThis is what the game window looks like. When the game is playing, the background color is blue. When you got correct, the background color changes to green and then move to next level. However when you got wrong, the backgroud changes to red and if you got wrong for 3 times, then it will show you the message “Game Over.”\n\n\n\nThe second component of the project is the development of a dynamic website. This is where users can select the options and view their game stats. Therefore we can say this is where integration of all the three components take place. However, what we initially planned to do was to integrate those three components to this website using tool called pygbag, which allows to play the gam on the web. We successfully embeded the game into web, however, it could not deal with saving the game data to csv file, so we were not able to create a plot for the game data. Therefore, we had to seperate those into three parts. Even though the gaming process got little complicated, the game worked well.\ndef write_to_csv(level, challenge):\n    \"\"\"\n    Save the selected game level and timer option to a CSV file.\n    \"\"\"\n    with open('game_setting.csv', 'a', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([level, challenge])\n        \n        \n@app.route(\"/select\", methods=['GET', 'POST'])\ndef select():\n    \"\"\"\n    Get and store the game level and challenge options.\n    \"\"\"\n    if request.method == 'POST':\n        selected_level = request.form.get(\"level\")\n        selected_challenge = request.form.get(\"challenge\")\n        write_to_csv(selected_level, selected_challenge) \n        return redirect('/confirm')\n    return render_template('select.html')\n\n\n&lt;form id=\"selectionForm\" action=\"/select\" method=\"post\"&gt;  &lt;!-- Form for submitting game selection options, posts data to /select --&gt;\n    &lt;div class=\"main center\"&gt;\n        &lt;div class=\"box\"&gt;\n            &lt;h2&gt;Select Level&lt;/h2&gt;  &lt;!-- Section game level --&gt;\n            &lt;ul&gt;\n                &lt;input type=\"radio\" name=\"level\" value=\"1\"&gt; Level 1&lt;br&gt;\n                &lt;input type=\"radio\" name=\"level\" value=\"2\"&gt; Level 2&lt;br&gt;\n                &lt;input type=\"radio\" name=\"level\" value=\"3\"&gt; Level 3&lt;br&gt;\n            &lt;/ul&gt;\n        &lt;/div&gt;\n        &lt;div class=\"box\"&gt;\n            &lt;h2&gt;Challenges&lt;/h2&gt;  &lt;!-- Section game challenges --&gt;\n            &lt;ul&gt;\n                &lt;input type=\"radio\" name=\"challenge\" value=\"timer\"&gt; Timer&lt;br&gt;\n                &lt;input type=\"radio\" name=\"challenge\" value=\"none\"&gt; None&lt;br&gt;\n            &lt;/ul&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"input-and-button-container\"&gt;  &lt;!-- Container for the submit button --&gt;\n            &lt;div class=\"start-button-container\"&gt;  \n                &lt;button type=\"submit\" class=\"btn\"&gt;Confirm&lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/form&gt;\nSelection Page (“/select”): Accessible through a POST and GET request, this route allows users to select the game level and timer option. The selections are captured from a form submission and stored, possibly in a CSV file for persistence across sessions. After making their selections, users are redirected to a confirmation page.\nThe html code for the select page shows the straightforward and user-friendly design of the game selection interface. With a radio button type, we made it able to select only one selection, and made a button and linked it to the next page, so it allows to move to confirm page whenever users click the confirm button.\n\n\n\nMain Page\n\n\nThis is what the main page of the website looks like. The two images on the bottom works as menu buttons to go move to next pages.\n\n\n\nThe third component of the project focuses on integrating data visualization into the web application. It first read the game data from a CSV file, analyzing this data, and make insightful visualizations on a web page dedicated to game statistics. There are three plots for the game stats visualization:Histogram of Levels Reached, Average Time Spent per Level, and Success Rate per Level.\nHistogram of Levels Reached shows the distribution of maximum levels reached by players.\nAverage Time Spent per Level shows the average time spent on correct versus incorrect attempts on each level\nSuccess Rate per Level shows the percentage of successful attempts per level.\n\nparsed_data = []\n# Read the CSV file again to parse its content\nwith open(file_path, 'r') as file:\n    for line in file:\n        elements = line.strip().split(',')\n        # Process every three elements (assuming level, result, time_spent format)\n        for i in range(0, len(elements), 3):\n            try:\n                level = int(elements[i])  # Convert the first of every three elements to an integer\n                result = elements[i+1]  # The second element is the result (e.g., win/lose)\n                time_spent = float(elements[i+2])  # The third element is time spent, converted to float\n                parsed_data.append([level, result, time_spent])\n            except ValueError:\n                print(f\"Skipping malformed line: {line.strip()}\")\n\n# Create a DataFrame from the parsed data\ndf = pd.DataFrame(parsed_data, columns=['Level', 'Result', 'Time Spent'])\n\n# Plot 2: Average Time Spent per Level for Correct vs Incorrect Attempts\n# Calculates the average time spent per level and result.\navg_time_spent = df.groupby(['Level', 'Result'])['Time Spent'].mean().reset_index()  \nfig2 = go.Figure()\n# Loops through each unique result (e.g., 'correct', 'incorrect') to add a bar for each level and result combination.\nfor result in avg_time_spent['Result'].unique():\n    df_filtered = avg_time_spent[avg_time_spent['Result'] == result]\n    # Adds a bar trace to the figure for each result with the average time spent per level.\n    fig2.add_trace(go.Bar(x=df_filtered['Level'], y=df_filtered['Time Spent'], name=result))\n# Configures the layout of the plot, including the title, axis labels, and setting the bar mode to group for comparison.\nfig2.update_layout(title_text='Average Time Spent per Level',\n                   xaxis_title='Level',\n                   yaxis_title='Average Time Spent (seconds)',\n                   barmode='group')\nfig2.show()\n\nreturn render_template('stats.html')\nThis shows the code for visializing the average time spent on correct versus incorrect attempts on each level. The parsed data is converted into a pandas DataFrame and it creates an interactive bar chart using Plotly. It calculates the average time spent per level and loops through each correct and incorrect.\n\n\n\nData Visualization\n\n\nThis plot is how the Histogram of Levels Reached looks like.\n\n\n\nIf you want to play the game , you should first need to download all the files in our github repository. Then go to command line, and navigate to where the folder you just downloaded is located at. And then type “flask run”.\nThen it will show you the url like http://127… Go to this website and this will show you the main website for the game. After selecting the game options, go to the command line again and type “python main.py”.\nNow the game will be launched with your selected game options. After finishing the game, if you wnat to view the game stats visualization, just click the Game Stats tab in the main homepage, then the plots will be shown.\n\n\n\nThe project we prerformed created simple memory games and didn’t even collect special personal information, so we think that there is not much ethical issues. This game can help with memory, but it can be bad to play for a long time because it is still a game."
  },
  {
    "objectID": "posts/Final Project/project post.html#overview",
    "href": "posts/Final Project/project post.html#overview",
    "title": "Final Group Project",
    "section": "",
    "text": "The project is about making a memory game that measures people’s short-term memory and helps remembering things better. The game provides users with randomly arranged numbers. After a certain amount of time, the numbers disappear, then users have to remember where each number was and click boxes in the correct order. We made this game using Pygame that allows us to make cool games.\nWe didn’t just make the game. We also created a website where players could choose some potions of the game and see how well they were doing with visualization. For the website, we used Flask, which allows to create a website in Python. After players play the game, users can move to a stats page and see charts and statistics about the game. We used library called Plotly to make these charts.\nBelow is a simple flow chart how our projet works and data is handled.\n\n\n\nFlow Chart"
  },
  {
    "objectID": "posts/Final Project/project post.html#first-component-pygame",
    "href": "posts/Final Project/project post.html#first-component-pygame",
    "title": "Final Group Project",
    "section": "",
    "text": "The pygame portion of your project serves as the core gameplay engine for the memory game. This game, inspired by the “chimp test,” challenges players to remember and select squares in the order of their numbers, which are initially displayed and then hidden.\nThe difficulty adjustment and going to the next level are one of the main features of the game. The difficulty affects the number of squares that appear as the player progresses, making the game even more difficult. This adjustment is made possible through the difficulty variable, which is read from a csv file and affects the number of squares that are generated at each new level.\n\n# Taking into account user's difficulty and/or challenge chosen                 \nwith open(\"game_setting.csv\", 'r') as file:                    \n    last_line = file.readlines()[-1]                        # Accessing the last entry row\n    difficulty = int(last_line.split(',')[0])               \n                                                            # Taking the 1st integer variable as difficulty\n    if last_line.split(',')[1] == 'timer\\n' :               # Checking if 2nd element says timer chosen\n        timer_chosen = 1\n    else :                                                  \n        timer_chosen = 0\n        \n\n# Winning Condition and Level Progression\nif len(num_list) == len(square_group):        # Checking if all squares were clicked\n    win = num_list == [str(squares.number) for squares in square_group] # Setting win condition\n    \n    if win:\n        reset_coord()                         \n        num_list = []\n        for i in range(difficulty):           # Adding number of squares equal to difficulty chosen\n            square_group.add(Square(len(square_group) + 1, make_square=False)) \nThe latter part of the code explains about the winning condition, This section checks if the player has clicked all the squares (len(num_list) == len(square_group)), num_list tracks the squares the player has clicked in order.\nThe win condition checks if the sequence of squares clicked by the player (num_list) matches the intended sequence, which is determined by the order of numbers assigned to each square in square_group.\nWhen the win condition meets, the game resets the coordinates for the squares (reset_coord()), clears the num_list, and adds new squares according to the difficulty level. The number of squares increases depending on the level of difficulty chosen.\n\n\n\nGame WIndow\n\n\nThis is what the game window looks like. When the game is playing, the background color is blue. When you got correct, the background color changes to green and then move to next level. However when you got wrong, the backgroud changes to red and if you got wrong for 3 times, then it will show you the message “Game Over.”"
  },
  {
    "objectID": "posts/Final Project/project post.html#second-component-flask-app",
    "href": "posts/Final Project/project post.html#second-component-flask-app",
    "title": "Final Group Project",
    "section": "",
    "text": "The second component of the project is the development of a dynamic website. This is where users can select the options and view their game stats. Therefore we can say this is where integration of all the three components take place. However, what we initially planned to do was to integrate those three components to this website using tool called pygbag, which allows to play the gam on the web. We successfully embeded the game into web, however, it could not deal with saving the game data to csv file, so we were not able to create a plot for the game data. Therefore, we had to seperate those into three parts. Even though the gaming process got little complicated, the game worked well.\ndef write_to_csv(level, challenge):\n    \"\"\"\n    Save the selected game level and timer option to a CSV file.\n    \"\"\"\n    with open('game_setting.csv', 'a', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([level, challenge])\n        \n        \n@app.route(\"/select\", methods=['GET', 'POST'])\ndef select():\n    \"\"\"\n    Get and store the game level and challenge options.\n    \"\"\"\n    if request.method == 'POST':\n        selected_level = request.form.get(\"level\")\n        selected_challenge = request.form.get(\"challenge\")\n        write_to_csv(selected_level, selected_challenge) \n        return redirect('/confirm')\n    return render_template('select.html')\n\n\n&lt;form id=\"selectionForm\" action=\"/select\" method=\"post\"&gt;  &lt;!-- Form for submitting game selection options, posts data to /select --&gt;\n    &lt;div class=\"main center\"&gt;\n        &lt;div class=\"box\"&gt;\n            &lt;h2&gt;Select Level&lt;/h2&gt;  &lt;!-- Section game level --&gt;\n            &lt;ul&gt;\n                &lt;input type=\"radio\" name=\"level\" value=\"1\"&gt; Level 1&lt;br&gt;\n                &lt;input type=\"radio\" name=\"level\" value=\"2\"&gt; Level 2&lt;br&gt;\n                &lt;input type=\"radio\" name=\"level\" value=\"3\"&gt; Level 3&lt;br&gt;\n            &lt;/ul&gt;\n        &lt;/div&gt;\n        &lt;div class=\"box\"&gt;\n            &lt;h2&gt;Challenges&lt;/h2&gt;  &lt;!-- Section game challenges --&gt;\n            &lt;ul&gt;\n                &lt;input type=\"radio\" name=\"challenge\" value=\"timer\"&gt; Timer&lt;br&gt;\n                &lt;input type=\"radio\" name=\"challenge\" value=\"none\"&gt; None&lt;br&gt;\n            &lt;/ul&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"input-and-button-container\"&gt;  &lt;!-- Container for the submit button --&gt;\n            &lt;div class=\"start-button-container\"&gt;  \n                &lt;button type=\"submit\" class=\"btn\"&gt;Confirm&lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/form&gt;\nSelection Page (“/select”): Accessible through a POST and GET request, this route allows users to select the game level and timer option. The selections are captured from a form submission and stored, possibly in a CSV file for persistence across sessions. After making their selections, users are redirected to a confirmation page.\nThe html code for the select page shows the straightforward and user-friendly design of the game selection interface. With a radio button type, we made it able to select only one selection, and made a button and linked it to the next page, so it allows to move to confirm page whenever users click the confirm button.\n\n\n\nMain Page\n\n\nThis is what the main page of the website looks like. The two images on the bottom works as menu buttons to go move to next pages."
  },
  {
    "objectID": "posts/Final Project/project post.html#third-component-data-visualization",
    "href": "posts/Final Project/project post.html#third-component-data-visualization",
    "title": "Final Group Project",
    "section": "",
    "text": "The third component of the project focuses on integrating data visualization into the web application. It first read the game data from a CSV file, analyzing this data, and make insightful visualizations on a web page dedicated to game statistics. There are three plots for the game stats visualization:Histogram of Levels Reached, Average Time Spent per Level, and Success Rate per Level.\nHistogram of Levels Reached shows the distribution of maximum levels reached by players.\nAverage Time Spent per Level shows the average time spent on correct versus incorrect attempts on each level\nSuccess Rate per Level shows the percentage of successful attempts per level.\n\nparsed_data = []\n# Read the CSV file again to parse its content\nwith open(file_path, 'r') as file:\n    for line in file:\n        elements = line.strip().split(',')\n        # Process every three elements (assuming level, result, time_spent format)\n        for i in range(0, len(elements), 3):\n            try:\n                level = int(elements[i])  # Convert the first of every three elements to an integer\n                result = elements[i+1]  # The second element is the result (e.g., win/lose)\n                time_spent = float(elements[i+2])  # The third element is time spent, converted to float\n                parsed_data.append([level, result, time_spent])\n            except ValueError:\n                print(f\"Skipping malformed line: {line.strip()}\")\n\n# Create a DataFrame from the parsed data\ndf = pd.DataFrame(parsed_data, columns=['Level', 'Result', 'Time Spent'])\n\n# Plot 2: Average Time Spent per Level for Correct vs Incorrect Attempts\n# Calculates the average time spent per level and result.\navg_time_spent = df.groupby(['Level', 'Result'])['Time Spent'].mean().reset_index()  \nfig2 = go.Figure()\n# Loops through each unique result (e.g., 'correct', 'incorrect') to add a bar for each level and result combination.\nfor result in avg_time_spent['Result'].unique():\n    df_filtered = avg_time_spent[avg_time_spent['Result'] == result]\n    # Adds a bar trace to the figure for each result with the average time spent per level.\n    fig2.add_trace(go.Bar(x=df_filtered['Level'], y=df_filtered['Time Spent'], name=result))\n# Configures the layout of the plot, including the title, axis labels, and setting the bar mode to group for comparison.\nfig2.update_layout(title_text='Average Time Spent per Level',\n                   xaxis_title='Level',\n                   yaxis_title='Average Time Spent (seconds)',\n                   barmode='group')\nfig2.show()\n\nreturn render_template('stats.html')\nThis shows the code for visializing the average time spent on correct versus incorrect attempts on each level. The parsed data is converted into a pandas DataFrame and it creates an interactive bar chart using Plotly. It calculates the average time spent per level and loops through each correct and incorrect.\n\n\n\nData Visualization\n\n\nThis plot is how the Histogram of Levels Reached looks like."
  },
  {
    "objectID": "posts/Final Project/project post.html#how-to-play",
    "href": "posts/Final Project/project post.html#how-to-play",
    "title": "Final Group Project",
    "section": "",
    "text": "If you want to play the game , you should first need to download all the files in our github repository. Then go to command line, and navigate to where the folder you just downloaded is located at. And then type “flask run”.\nThen it will show you the url like http://127… Go to this website and this will show you the main website for the game. After selecting the game options, go to the command line again and type “python main.py”.\nNow the game will be launched with your selected game options. After finishing the game, if you wnat to view the game stats visualization, just click the Game Stats tab in the main homepage, then the plots will be shown."
  },
  {
    "objectID": "posts/Final Project/project post.html#remarks",
    "href": "posts/Final Project/project post.html#remarks",
    "title": "Final Group Project",
    "section": "",
    "text": "The project we prerformed created simple memory games and didn’t even collect special personal information, so we think that there is not much ethical issues. This game can help with memory, but it can be bad to play for a long time because it is still a game."
  },
  {
    "objectID": "posts/hw0/HW0_post-new.html",
    "href": "posts/hw0/HW0_post-new.html",
    "title": "HW0 Creating Post",
    "section": "",
    "text": "In this post, we will explore the dataset of penguins that captures various aspects of their physical characteristics. We will visualize the dataset and the explore the relationship between different characteristics by using the Plotly library. We will focus on capturing the differences in Culmen Length and Culmen Depth among penguins based on their sex and the place they live. We will create some visualization to see if there is any significant difference of Culmen Length and Culmen Depth between sex or where they live."
  },
  {
    "objectID": "posts/hw0/HW0_post-new.html#introduction",
    "href": "posts/hw0/HW0_post-new.html#introduction",
    "title": "HW0 Creating Post",
    "section": "",
    "text": "In this post, we will explore the dataset of penguins that captures various aspects of their physical characteristics. We will visualize the dataset and the explore the relationship between different characteristics by using the Plotly library. We will focus on capturing the differences in Culmen Length and Culmen Depth among penguins based on their sex and the place they live. We will create some visualization to see if there is any significant difference of Culmen Length and Culmen Depth between sex or where they live."
  },
  {
    "objectID": "posts/hw0/HW0_post-new.html#load-the-dataset",
    "href": "posts/hw0/HW0_post-new.html#load-the-dataset",
    "title": "HW0 Creating Post",
    "section": "Load the Dataset",
    "text": "Load the Dataset\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\n\n# Load the dataset into a pandas DataFrame\npenguins = pd.read_csv(url)\n\n# First few rows of the data\npenguins.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/07\n39.1\n18.7\n181.0\n3750.0\nMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/07\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n11/16/07\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n3\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n11/16/07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAdult not sampled.\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n11/16/07\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN"
  },
  {
    "objectID": "posts/hw0/HW0_post-new.html#visualizing-culmen-size-by-sex",
    "href": "posts/hw0/HW0_post-new.html#visualizing-culmen-size-by-sex",
    "title": "HW0 Creating Post",
    "section": "Visualizing Culmen Size by Sex",
    "text": "Visualizing Culmen Size by Sex\nFirst, we will going to see if there is a difference of Culmen Length and Depth between male and female penguins. We will plot the data in 2D plots with different scatter colors using the plotly library.\n\nimport plotly\nfrom plotly import express as px\n\nfig1 = px.scatter(data_frame = penguins,      \n                 x = \"Culmen Length (mm)\",    # column for x axis\n                 y = \"Culmen Depth (mm)\",     # column for y axis\n                 color = \"Sex\",               # column for dot color : \n                                              #   visualize the difference by sex\n                 width = 500,                 # width of figure\n                 height = 300,                # height of figure\n                 opacity = 0.5                # opacity of figure\n                )\n\n#reduce whitespace and add title\nfig1.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0}, \n                  title = \"Culmen Length and Depth by Sex\")\nfig1.show()\n\n# Save the figure as HTML\nfrom plotly.io import write_html\nwrite_html(fig1, \"plot1.html\")\n\n                                                \n\n\nAs you can see above, overall, male penguin have deeper and longer Culmen. However, there is no clear boundary between the sex. That is because the length and the depth can be affected by other factors, especially the species of penguins."
  },
  {
    "objectID": "posts/hw0/HW0_post-new.html#visualizing-culmen-size-by-habitat",
    "href": "posts/hw0/HW0_post-new.html#visualizing-culmen-size-by-habitat",
    "title": "HW0 Creating Post",
    "section": "Visualizing Culmen Size by Habitat",
    "text": "Visualizing Culmen Size by Habitat\nNext, we’re curious about how the habitat of a penguin might influence its Culmen size. We will again plot the 2D scatter plot using the ploty library.\n\nfig2 = px.scatter(data_frame = penguins,\n                 x = \"Culmen Length (mm)\",   \n                 y = \"Culmen Depth (mm)\",    \n                 color = \"Island\",          # column for dot color : \n                                            #   visualize the difference by habitat\n                 width = 500,\n                 height = 300,\n                 opacity = 0.5\n                )\n\nfig2.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0}, \n                  title = \"Culmen Length and Depth by Habitat\")\nfig2.show()\n\nwrite_html(fig2, \"plot2.html\")\n\n                                                \n\n\nIn the plot, we can see that overall, the penguins in Drean island have the biggest Culmen. In Torgersen, those with similar Culmen live. However, in Biscoe and Dream island penguins with various size of Culmen live together."
  },
  {
    "objectID": "posts/hw0/HW0_post-new.html#conclusion",
    "href": "posts/hw0/HW0_post-new.html#conclusion",
    "title": "HW0 Creating Post",
    "section": "Conclusion",
    "text": "Conclusion\nThrough the visualiazation, we have observed the differences in Culmen size among penguins based on sex and their living islands. However, it looks like there isn’t clear and significant difference of the Culmen size by sex or habitat itself. We might need to add some more classifiers in order to detect the difference in the Culmen size."
  },
  {
    "objectID": "posts/hw6/index6.html",
    "href": "posts/hw6/index6.html",
    "title": "HW5 : Text Classification : Spotting Fake News",
    "section": "",
    "text": "In this blog post, I will show you how to detect fake news using Keras text classification.\n\n!pip install keras --upgrade\n\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\nCollecting keras\n  Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 3.6 MB/s eta 0:00:00\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\nCollecting namex (from keras)\n  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (2.16.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)\nInstalling collected packages: namex, keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.15.0\n    Uninstalling keras-2.15.0:\n      Successfully uninstalled keras-2.15.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras&lt;2.16,&gt;=2.15.0, but you have keras 3.0.5 which is incompatible.\nSuccessfully installed keras-3.0.5 namex-0.0.7\n\n\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport re\nimport string\nimport keras\nfrom keras import layers, losses\nfrom keras.layers import TextVectorization\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder"
  },
  {
    "objectID": "posts/hw6/index6.html#comments",
    "href": "posts/hw6/index6.html#comments",
    "title": "HW5 : Text Classification : Spotting Fake News",
    "section": "Comments",
    "text": "Comments\nThe word “video” is located at the very right side of the x-axis, which could mean that it is a strong feature when determining fake news.\nSimilarly, the word “trump”, “obama”, and “hillary” are also located at the far end of the x-axis, implying that articles mentioning politician’s name could play a significant role in classifying the news.\n“mass”, “several”, “send” are located right in the middle. These words implies that they have less discriminative power in distinguishing between real and fake news. These words are used relatively equally in both fake and real news.\n“frances”, “zimbabwes”, and “myanmar” in the bottom left corner of the plot suggests they are outliers. They might appear only in specific types of articles, such as international or politic news.\n“fbi”, “die”, and “federal” are clustered near the top center of the plot. This might suggest that they have some discriminative power, due to their association with more formal or serious news content."
  },
  {
    "objectID": "posts/hw3/index.html",
    "href": "posts/hw3/index.html",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "",
    "text": "URL for the Github repo : https://github.com/askpl00/flask_hw3_16B/tree/main"
  },
  {
    "objectID": "posts/hw3/index.html#overview-of-the-message-bank-web",
    "href": "posts/hw3/index.html#overview-of-the-message-bank-web",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "Overview of the Message Bank Web",
    "text": "Overview of the Message Bank Web\nThere are two big features in my web app.\n\nMessage Submission : Users can submit messages with their names.\nMessage Viewing : Users can view their provious subimitted messages."
  },
  {
    "objectID": "posts/hw3/index.html#the-main-page-route",
    "href": "posts/hw3/index.html#the-main-page-route",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "The Main Page : route(‘/’)",
    "text": "The Main Page : route(‘/’)\nTo start with, I set the main page of the website. The route (/) is the entry point, which is the first page a user sees when they visit the web app.\n@app.route('/')\ndef index():\n    return render_template('base.html')\nWhen a visitor goes to the home page, Flask executes the index function. This function uses Flask’s @app.route to tell Flask which URL should trigger our function. Then it renders base.html whuch also contains the navigation and layout."
  },
  {
    "objectID": "posts/hw3/index.html#base.html",
    "href": "posts/hw3/index.html#base.html",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "base.html",
    "text": "base.html\n&lt;!doctype html&gt;\n&lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\"&gt;\n&lt;title&gt;{% block title %}{% endblock %} A Simple Message Bank&lt;/title&gt;\n&lt;nav&gt;   # Navigation section of the webpage\n  &lt;h1&gt;A Simple Message Bank&lt;/h1&gt;  # The site's main title or heading (same with the title above)\n  &lt;!-- &lt;b&gt;Navigation:&lt;/b&gt; --&gt;\n  &lt;ul&gt;\n    &lt;li&gt;&lt;a href=\"{{ url_for('submit') }}\"&gt;Submit a message&lt;/a&gt;&lt;/li&gt;  # Navigation link to the page for submitting messages\n    &lt;li&gt;&lt;a href=\"{{ url_for('view')}}\"&gt;View messages&lt;/a&gt;&lt;/li&gt;  # Navigation link to the page for viewing messages \n\n  &lt;/ul&gt;\n&lt;/nav&gt;\n&lt;section class=\"content\"&gt;\n  &lt;header&gt;\n    {% block header %}{% endblock %}\n  &lt;/header&gt;\n  {% block content %}{% endblock %}\n&lt;/section&gt;\nIn base.html, a navigation bar is established, providing users to submit and view messages. It also sets a title, “A Simple Message Bank”. Page sections for content and headers are defined, and it enables to navigate link to the page for submitting messages or for viewing messages."
  },
  {
    "objectID": "posts/hw3/index.html#message-submission-page-routesubmit",
    "href": "posts/hw3/index.html#message-submission-page-routesubmit",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "Message Submission Page : route(‘/submit’)",
    "text": "Message Submission Page : route(‘/submit’)\nThe message submission feature consists a simple form where users can enter their name and message.\nThe submit view function allows users to submit messages. It responds to both GET and POST requests. When the route receives a GET request, it renders the submit.html template, which contains a form for the user to submit their message. For a POST request, which happens when a user submits the form, it processes the submitted data by calling insert_message(request) and renders the template with a message.\n@app.route('/submit', methods=['GET', 'POST'])\ndef submit():\n    if request.method == 'POST':\n        # If submitted, process the submitted data\n        insert_message(request)\n        return render_template('submit.html', thanks=True)\n    # If the page is requested just as GET, just show the form\n    return render_template('submit.html')\n\n\n\nUser submitting a message"
  },
  {
    "objectID": "posts/hw3/index.html#insert_message-function",
    "href": "posts/hw3/index.html#insert_message-function",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "insert_message function",
    "text": "insert_message function\nThe insert_message function extracts the submitted message and the user’s name and inserts them into database.\ndef insert_message(request):\n\n    db = get_message_db()\n    cursor = db.cursor()\n    \n    # Extract the message and the handle from the given data\n    handle = request.form['handle']\n    message = request.form['message']\n    \n    # Insert the new message into the messages table\n    cursor.execute(\"INSERT INTO messages (handle, message) VALUES (?, ?)\", (handle, message))\n    db.commit()\n    cursor.close()  # Close the cursor\ncursor.execute() prepares an SQL statement to insert the new message into the messages table. It tells the database to add a new message and uses handle and message from the user’s input, and insert them into the database."
  },
  {
    "objectID": "posts/hw3/index.html#get_message_db-function",
    "href": "posts/hw3/index.html#get_message_db-function",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "get_message_db function",
    "text": "get_message_db function\nThis function gets a connection to the database with the messages. This function tries to return database connection from Flask’s g object. If it doesn’t exist, it makes a new connection and ensures our messages table is created.\ndef get_message_db():\n\n    try:\n        # Try to return the database connection\n        return g.message_db\n    except:\n        # If it doesn't exist, create a new database \n        g.message_db = sqlite3.connect(\"messages_db.sqlite\")\n        \n        # Command to create a messages table if it does not exist\n        cmd = \"\"\"\n        CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY,\n            handle TEXT,\n            message TEXT\n        )\n        \"\"\"\n        \n        # Create a cursor to execute the SQL command\n        cursor = g.message_db.cursor()\n        cursor.execute(cmd)\n        \n        # Return the connection\n        return g.message_db\nIf a connection to the messages database doesn’t already exist within g, the function establishes a new SQLite connection to “messages_db.sqlite”. Additionally, it ensures the structure of the database is prepared for use by creating a messages table. Therefore, after running the code, it returns sqlite3 connection to the messages database."
  },
  {
    "objectID": "posts/hw3/index.html#message-view-page-routeview",
    "href": "posts/hw3/index.html#message-view-page-routeview",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "Message View Page : route(‘/view’)",
    "text": "Message View Page : route(‘/view’)\nView route and the random_messages function allows to show random messages\n@app.route('/view')\ndef view():\n    msgs = random_messages(5)  # 5 random messages from the database\n    return render_template('view.html', messages=msgs)\nWhen a user navigates to the ‘/view’ URL, the view() function is called. The view route in a Flask application displays messages from the database. It uses random_messages(5) to fetch a random sample of 5 messages. These messages goes to render_template to be displayed on ‘view.html’, offering differnt messages and names."
  },
  {
    "objectID": "posts/hw3/index.html#random_messages-function",
    "href": "posts/hw3/index.html#random_messages-function",
    "title": "HW3 : Message Bank Web Development Using Flask",
    "section": "random_messages function",
    "text": "random_messages function\ndef random_messages(n):\n\n    db = get_message_db()\n    cursor = db.cursor()\n    \n    # Fetch n random messages from the database\n    # If there are fewer than n messages, fetch all available messages.\n    query = \"SELECT handle, message FROM messages ORDER BY RANDOM() LIMIT ?\"\n   \n    # Fetch the results of the query\n    cursor.execute(query, (n,))\n    random_msgs = cursor.fetchall()\n    \n    db.close()  # Close the database connection\n    return random_msgs\nThe random_messages function picks a certain number of messages randomly from a list saved in the database, showing different messages each time users refresh. It connects to the database, chooses messages randomly up to the number asked for, stops the connection to save resources, and then gives back the messages it picked.\n\n\n\nUser viewing messages"
  },
  {
    "objectID": "posts/hw6/index_hw6.html",
    "href": "posts/hw6/index_hw6.html",
    "title": "HW5 : Text Classification : Spotting Fake News",
    "section": "",
    "text": "In this blog post, I will show you how to detect fake news using Keras text classification.\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport re\nimport string\nimport keras\nfrom keras import layers, losses\nfrom keras.layers import TextVectorization\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder"
  },
  {
    "objectID": "posts/hw6/index_hw6.html#comments",
    "href": "posts/hw6/index_hw6.html#comments",
    "title": "HW5 : Text Classification : Spotting Fake News",
    "section": "Comments",
    "text": "Comments\nThe word “video” is located at the very right side of the x-axis, which could mean that it is a strong feature when determining fake news.\nSimilarly, the word “trump”, “obama”, and “hillary” are also located at the far end of the x-axis, implying that articles mentioning politician’s name could play a significant role in classifying the news.\n“mass”, “several”, “send” are located right in the middle. These words implies that they have less discriminative power in distinguishing between real and fake news. These words are used relatively equally in both fake and real news.\n“frances”, “zimbabwes”, and “myanmar” in the bottom left corner of the plot suggests they are outliers. They might appear only in specific types of articles, such as international or politic news.\n“fbi”, “die”, and “federal” are clustered near the top center of the plot. This might suggest that they have some discriminative power, due to their association with more formal or serious news content."
  },
  {
    "objectID": "posts/hw1/index.html",
    "href": "posts/hw1/index.html",
    "title": "HW1 : Visualizing Climate Data using Query & Database",
    "section": "",
    "text": "In this blog post, we’ll look through interesting dataset on global temperatures and explore various ways of visualize using Python, SQLite, and Plotly. We will create interactive visualizations that can help us understand worldwide temperature over time.\n\n# To properly show figures in your blog,\n\nimport plotly.io as pio\npio.renderers.default=\"iframe\""
  },
  {
    "objectID": "posts/hw1/index.html#yearly-temperature-variation",
    "href": "posts/hw1/index.html#yearly-temperature-variation",
    "title": "HW1 : Visualizing Climate Data using Query & Database",
    "section": "1) Yearly Temperature Variation",
    "text": "1) Yearly Temperature Variation\nQuestion: How has the temperature variation (difference between the highest and lowest temperatures) changed over the years for a given country?\nTo answer this question, yearly_temperature_variation will calculate the yearly temperature variation for a specified country and range of years.\nThis is what the yearly_temperature_variation query function looks like :\n\nfrom climate_database import yearly_temperature_variation\nimport inspect\nprint(inspect.getsource(yearly_temperature_variation))\n\ndef yearly_temperature_variation(db_file, country, start_year, end_year):\n    \"\"\"\n    Yearly temperature variation (difference between max and min temperatures) \n    for a given country and start year and end year.\n    \n    Returns: Dataframe with two columns: Year and Variation,\n    \"\"\"\n    conn = sqlite3.connect(db_file)\n    query = f\"\"\"\n    SELECT T.Year, (MAX(T.Temp) - MIN(T.Temp)) AS Variation\n    FROM temperatures T\n    JOIN stations S ON T.ID = S.ID\n    JOIN countries C ON substr(T.ID, 1, 2) = C.[FIPS 10-4]\n    WHERE C.Name = ? AND T.Year BETWEEN ? AND ?\n    GROUP BY T.Year\n    ORDER BY T.Year;\n    \"\"\"\n    df = pd.read_sql_query(query, conn, params=(country, start_year, end_year))\n    conn.close()\n    return df\n\n\n\nWith the plot_yearly_temperature_variation, we can create a line plot showing the temperature variation of a specific country.\n\ndef plot_yearly_temperature_variation(db_file, country, start_year, end_year):\n    \"\"\"\n    Creates a line plot showing the yearly temperature variation.\n    \"\"\"\n    \n    df = yearly_temperature_variation(db_file, country, start_year, end_year)\n    fig = px.line(df, x='Year', y='Variation', \n                  title=f'Yearly Temperature Variation in {country}')\n    fig.update_xaxes(title_text='Year')\n    fig.update_yaxes(title_text='Temperature Variation (°C)')\n    return fig\n\n\nplot_yearly_temperature_variation(\"climate_data.db\", \"Japan\", 1960, 2000)"
  },
  {
    "objectID": "posts/hw1/index.html#extreme-temperature-on-specific-year-by-month",
    "href": "posts/hw1/index.html#extreme-temperature-on-specific-year-by-month",
    "title": "HW1 : Visualizing Climate Data using Query & Database",
    "section": "2) Extreme Temperature on Specific year by Month",
    "text": "2) Extreme Temperature on Specific year by Month\nQuestion : “What are the hottest and coldest temperatures for each month in a given year?”\nThe second query function is plot_extreme_temperatures(df, year) function which get the extreme temperature, the highest and the lowest, in the world when you put the input year. It will show you facet plot with the lowest and the highest temperatre plots in seperate figure.\n\nfrom climate_database import extreme_temperatures\nimport inspect\nprint(inspect.getsource(extreme_temperatures))\n\ndef extreme_temperatures(db_file, year):\n    \"\"\"\n    Lowest and highest temperatures for each month in specific year.\n    \n    Returns: Dataframe containing the lowest and highest temperatures for each month \n    in the world.\n    \"\"\"\n    conn = sqlite3.connect(db_file)\n    cmd = f\"\"\"\n    SELECT {year} AS Year, Month,\n           MIN(Temp) AS Min_Temperature,\n           MAX(Temp) AS Max_Temperature\n    FROM temperatures\n    WHERE Year = '{year}'\n    GROUP BY Month\n    ORDER BY Month\n    \"\"\"\n    df = pd.read_sql_query(cmd, conn)\n    # Prepare the DataFrame for faceting by melting it\n    df_melted = df.melt(id_vars=['Month'], value_vars=['Min_Temperature', 'Max_Temperature'],\n                        var_name='Temperature_Type', value_name='Temperature')\n    conn.close()\n    return df_melted\n\n\n\n\nimport plotly.express as px\n\ndef plot_extreme_temperatures(df, year):\n    \"\"\"\n    Creates a faceted line plot showing the lowest and highest temperatures for each month.\n    \n    Parameters:\n    - df (DataFrame): DataFrame containing the lowest and highest temperatures for each month, \n        which we got from the query.\n    - year (int): The year for which extreme temperatures are visualized.\n    \"\"\"\n    # Use the DataFrame directly for plotting with Plotly Express\n    fig = px.line(df, x='Month', y='Temperature', color='Temperature_Type', \n                  facet_col='Temperature_Type', title=f'Extreme Temperatures in {year}')\n    \n    # Update layout for better readability\n    fig.update_layout(xaxis_title='Month', yaxis_title='Temperature (°C)')\n    fig.show()\n\n\n# Plot using the year you want \n# Ex. year 2000\nplot_extreme_temperatures(extreme_temperatures(\"climate_data.db\", 2000), 2000)"
  },
  {
    "objectID": "posts/noname/index.html",
    "href": "posts/noname/index.html",
    "title": "HW2 : Scrapying TMDB Website & Movie Recommandation",
    "section": "",
    "text": "In this blog post, I will show you how to web scrape but I am going to create my own movie scraper. I will going to create TmdbSpider class which will scrape all the casts and the movies that the casts were in. To do so, I will create 3 different parse and the output will be saved in a seperate csv file."
  },
  {
    "objectID": "posts/noname/index.html#setup-and-overview",
    "href": "posts/noname/index.html#setup-and-overview",
    "title": "HW2 : Scrapying TMDB Website & Movie Recommandation",
    "section": "Setup and Overview",
    "text": "Setup and Overview\nThe TMDB page we are going to use is https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone/ which is Harry Potter and the Philosopher’s Stone.\nWe will first look through how the website looks like. Once you choose the movie, you can find the Full Cast & Crew link. Yhis will lead to page\n(original_url)cast/\nIf you scroll down, you will see the Cast section. If you click one of those, Alan Rickman, for example, then the full URL is going to be\nhttps://www.themoviedb.org/person/4566-alan-rickman\nOnce you get into the actors’s page, you will see the list of the actors’ acting, crew, production, (etc..) list."
  },
  {
    "objectID": "posts/noname/index.html#write-the-scraper",
    "href": "posts/noname/index.html#write-the-scraper",
    "title": "HW2 : Scrapying TMDB Website & Movie Recommandation",
    "section": "Write the Scraper",
    "text": "Write the Scraper\nNow we will write a scraper using the scrapy.\nThe basic format of the scraper look like :\n\nimport scrapy\n\nclass TmdbSpider(scrapy.Spider):\n    name = 'tmdb_spider'\n    def __init__(self, subdir=None, *args, **kwargs):\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\n\nAlong here, we need to implement three parsing methods for the TmdbSpider class, which are parse(self, response), parse_full_credits(self, response), parse_actor_page(self, response).\n\nparse(self, response)\n\nInstruction :\nparse(self, response) should assume that you start on a movie page, and then navigate to the Full Cast & Crew page. Remember that this page has url cast. (You are allowed to hardcode that part.) Once there, the parse_full_credits(self,response) should be called, by specifying this method in the callback argument to a yielded scrapy.Request. The parse() method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings.\n\ndef parse(self, response):\n    \"\"\"\n    Construct the full cast URL and navigate to the cast URL.\n    \"\"\"\n    # Make the full cast URL by adding \"/cast\" \n    full_cast_url = response.url + \"/cast\"\n    \n    # Yield a new scrapy.Request for the cast URL, and use the callback method to handle the response\n    yield scrapy.Request(full_cast_url, callback=self.parse_full_credits)\n\nThe first method is pretty clear. We start from the movie main page. What this method have to do is to navigate to the Full Cast & Crew page. Once you click the page in the website, you can find out the page URL is just\n(original_url)cast/\nTherefore what we need to do here is to just add cast/ to the initial URL we have and yield a Request by spider’s callback. We can specify what should happen when we get there as a callback, which is to yielded scrapy.Request.\n\n\n\ndef parse_full_credits(self, response)\n\nInstruction :\nparse_full_credits(self, response) should assume that you start on the Full Cast & Crew page. Its purpose is to yield a scrapy.Request for the page of each actor listed on the page. Crew members are not included. The yielded request should specify the method parse_actor_page(self, response) should be called when the actor’s page is reached. The parse_full_credits() method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings.\n\ndef parse_full_credits(self, response):\n    \"\"\"\n    Select only the cast section, excluding crew, and extracts URLs to actor pages.\n    Navigates to each actor's page by using for loop.\n    \"\"\"\n    # Use selectors to extract only the cast members, which does not have class 'crew'\n    cast = response.css('ol.people.credits:not(.crew)')\n    \n    # Extract the 'href' links to the individual actor pages\n    hrefs = cast.css('div.info a::attr(href)').getall()\n\n    # Iterate for each actor page\n    for link in hrefs:\n        yield scrapy.Request(response.urljoin(link), callback=self.parse_actor_page)\n\nNow this method starts from the Full Cast & Crew page. We first need to request the page or each actor(only actor, not crew). Here we are going to use the selector. Each actor’s selector is in this format:\n&lt;div class=\"info\"&gt;\n            &lt;p&gt;&lt;a href=\"/person/194-richard-harris\"&gt;Richard Harris&lt;/a&gt;&lt;/p&gt;&lt;p&gt;\n            &lt;/p&gt;&lt;p class=\"character\"&gt;Albus Dumbledore\n            &lt;/p&gt;\n          &lt;/div&gt;\nHowever, not only actor has this format, but also crew has this format. So we have to look for higher class. Then we can find that the casting is under\n&lt;ol class=\"people credits \"&gt;\nand the crew is under\n&lt;ol class=\"people credits crew\"&gt;\nSo I first set the\ncast = response.css('ol.people.credits:not(.crew)') \nand then set\nhrefs = cast.css('div.info a::attr(href)').getall().\nsince what we see is in a hyperlink format, I wrote as a::attr(href) under div class info. I used getall() because we need to navigate to all the cast.\nThe for loop is to navigate each of the cast’s page and here request and callback self.parse_actor_page.\n\n\n\ndef parse_actor_page(self, response):\n\nInstruction :\nparse_actor_page(self, response) should assume that you start on the page of an actor. It should yield a dictionary with two key-value pairs, of the form {“actor” : actor_name, “movie_or_TV_name” : movie_or_TV_name}. The method should yield one such dictionary for each of the movies or TV shows on which that actor has worked in an “Acting” role1. Note that you will need to determine both the name of the actor and the name of each movie or TV show. This method should be no more than 15 lines of code, excluding comments and docstrings.\n\ndef parse_actor_page(self, response):\n    \"\"\"\n    Extract the actor's name on the actor's page.\n    Extract movie's name that the actor had an acting role \n    by selecting the table that follows after the \"Acting\".\n    Create a set to avoid duplicates and yields actor's name and movie's name.\n    \"\"\"\n    # Extract actor's name from h2 tag class title\n    actor_name = response.css('h2.title ::text').get()\n\n    # Extract the table that follows the h3\n    acting_section = response.xpath(\"//h3[contains(text(), 'Acting')]/following-sibling::table[1]\")\n\n    # Create a set to store movie titles.\n    unique_movies = set()\n\n    for movie in acting_section.css(\"tr\"):\n        # Extract the text, which is the movie name\n        movie_name = movie.css('td a ::text').get()  \n\n        # Add the movie name to the set if it is not already in the set\n        if movie_name not in unique_movies:\n            unique_movies.add(movie_name)  \n\n            yield {\n                'actor': actor_name,\n                'movie_or_TV_name': movie_name\n            }\n\nWe start from actor’s page. First we will going to extract the actor’s name by calling\nactor_name = response.css('h2.title ::text').get()\nThe name is in h2.title format. So we extract just the text by ::text.\nNext we need to find what movie they acted in. We should only yield movies or TV shows on which that actor has worked in an “Acting” role. However, “Acting”, “crew”, “Production” are all under same  format:\n&lt;tbody&gt;&lt;tr&gt;\n          &lt;td&gt;\n            &lt;table class=\"credit_group\"&gt;\n              &lt;tbody&gt;&lt;tr&gt;\n                &lt;td class=\"year\"&gt;—&lt;/td&gt;\n                  &lt;td class=\"seperator\"&gt;&lt;span data-url=\"/tv/44337\" data-id=\"52596773760ee346619c97e4\" data-type=\"tv\" data-slug=\"44337\" class=\"glyphicons_v2 circle-empty account_adult_false item_adult_false\"&gt;&lt;/span&gt;&lt;/td&gt;\n                &lt;td class=\"role true account_adult_false item_adult_false\"&gt;\n                  &lt;a class=\"tooltip\" href=\"/tv/44337\"&gt;&lt;bdi&gt;Have I Got a Bit More News for You&lt;/bdi&gt;&lt;/a&gt;\n                    &lt;span class=\"group\"&gt; &lt;span&gt;(&lt;a class=\"tv\" href=\"/tv/44337/episodes?credit_id=5bce0b02c3a3683d6f000fd7&amp;person_id=4bc89155017a3c122d00c255\"&gt;2 episodes&lt;/a&gt;)&lt;/span&gt; as &lt;span class=\"character\"&gt;Self - Presenter&lt;/span&gt;&lt;/span&gt;\n                &lt;/td&gt;\n              &lt;/tr&gt;\n            &lt;/tbody&gt;&lt;/table&gt;\n          &lt;/td&gt;\n        &lt;/tr&gt;\n    &lt;/tbody&gt;\n    \nThe only thing that is different is each acting, crew or production are under the different h3 class zero title.\n&lt;h3 class=\"zero\"&gt;Acting&lt;/h3&gt;\n&lt;h3 class=\"zero\"&gt;Crew&lt;/h3&gt;\n&lt;h3 class=\"zero\"&gt;Production&lt;/h3&gt;\nHowever, the tables are not under these selectors, but the tables follow right after the titles. So we can extract the ‘Acting’ section by selecting the table right after this class.\nacting_section = response.xpath(\"//h3[contains(text(), 'Acting')]/following-sibling::table[1]\")\nThe code above is first filter the previously selected h3 elements. It selects only those content that contains the word “Acting”. And then find siblings that come after the selected node. Then select the first table element, table[1], which is a following sibling of the h3 containing the word “Acting”.\nIn this way we can get the movie name of only “Acting”."
  },
  {
    "objectID": "posts/noname/index.html#run-the-scraper",
    "href": "posts/noname/index.html#run-the-scraper",
    "title": "HW2 : Scrapying TMDB Website & Movie Recommandation",
    "section": "Run the Scraper",
    "text": "Run the Scraper\nNow we can run the following command in the terminal inside the directory you want.\nscrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\nThis command will make a csv file named results in the folder you want."
  },
  {
    "objectID": "posts/noname/index.html#make-the-recommendations",
    "href": "posts/noname/index.html#make-the-recommendations",
    "title": "HW2 : Scrapying TMDB Website & Movie Recommandation",
    "section": "Make the Recommendations",
    "text": "Make the Recommendations\nBased on the data of actors and the movie they acted in, we can make a recommandation of the specific movie(here it is Harry Potter and the Philosopher’s Stone).\n\nimport pandas as pd\n\n# Load the CSV file\nresults_df = pd.read_csv('/Users/gimdong-gyu/Desktop/TMDB_scraper/results.csv')\n\nresults_df\n\n\n\n\n\n\n\n\nactor\nmovie_or_TV_name\n\n\n\n\n0\nDaniel Radcliffe\nHave I Got a Bit More News for You\n\n\n1\nDaniel Radcliffe\nDavid Holmes: The Boy Who Lived\n\n\n2\nDaniel Radcliffe\n100 Years of Warner Bros.\n\n\n3\nDaniel Radcliffe\nMulligan\n\n\n4\nDaniel Radcliffe\nDigman!\n\n\n...\n...\n...\n\n\n2917\nRupert Grint\nThe View\n\n\n2918\nRupert Grint\nGMTV\n\n\n2919\nRupert Grint\nThe Tonight Show with Jay Leno\n\n\n2920\nRupert Grint\nAn Audience with...\n\n\n2921\nRupert Grint\nToday\n\n\n\n\n2922 rows × 2 columns\n\n\n\nWe can see there are 2922 rows, which means there are total 2922 movies that every cast had a roll in.\nBut we need to group those actors that were in the same movie and count them in order to see which movie has the most shared actor. Also we can make a recommandation based on the most shared movies.\n\n# group by the 'movie_or_TV_name' and count the number of unique actors.\nshared_actors = results_df.groupby('movie_or_TV_name')['actor'].nunique().reset_index()\nshared_actors.columns = ['movie names', 'number of shared actors']\n\n# Sort by the number of shared actors \nshared_sorted = shared_actors.sort_values(by='number of shared actors', ascending=False)\nshared_sorted\n\n\n\n\n\n\n\n\nmovie names\nnumber of shared actors\n\n\n\n\n700\nHarry Potter and the Philosopher's Stone\n63\n\n\n694\nHarry Potter and the Chamber of Secrets\n37\n\n\n382\nCreating the World of Harry Potter\n36\n\n\n701\nHarry Potter and the Prisoner of Azkaban\n26\n\n\n699\nHarry Potter and the Order of the Phoenix\n24\n\n\n...\n...\n...\n\n\n796\nIndiana Jones and the Kingdom of the Crystal S...\n1\n\n\n795\nIndian Summers\n1\n\n\n794\nIn the Red\n1\n\n\n793\nIn the Heart of the Sea\n1\n\n\n2273\nZastrozzi: A Romance\n1\n\n\n\n\n2274 rows × 2 columns\n\n\n\nNow we want to visualize the top 10 movies that shows the most shared actors. To do this, We can use matplotlib to create a bar chart\n\nimport matplotlib.pyplot as plt\n\n# Get the top 10 movies/TV shows\ntop10 = shared_sorted.head(10)\n\n# Plotting the bar chart\nplt.figure(figsize=(10, 6))\nplt.barh(top10['movie names'], top10['number of shared actors'])\nplt.title('Top 10 Movies with the Most Shared Actors')\nplt.xlabel('Shared Actors Count')\nplt.ylabel('Movie')\nplt.show()\n\n\n\n\n\n\n\n\nBased on the graph, we can see that the Harry Potter and the Chamber of Secrets is the movie that has most shared actors with Harry Potter and the Philosopher’s Stone.\nHowever, this recommandation is not really useful because except for one movie, those movies in top 10 are all Harry Potter Series.\nTherefore We will make a seperate recommandation plot that does not contain Harry Potter Series.\n\nRecommandation Other than Harry Potter Series\n\n# Remove movies that contain \"Harry Potter\" in the title.\nno_harry = shared_sorted[~shared_sorted['movie names'].str.contains('Harry Potter')]\n\ntop10 = no_harry.head(10)\n\nplt.figure(figsize=(10, 6))\nplt.barh(top10['movie names'], top10['number of shared actors'])\nplt.title('Top 10 Movies with the Most Shared Actors (Other than Harry Potter)')\nplt.xlabel('Shared Actors Count')\nplt.ylabel('Movie')\nplt.show()\n\n\n\n\n\n\n\n\nFrom the plot, now we can see that the most most shared actor movie is Doctor Who and all the movies in the top 10 are now movies other than Harry Potter."
  },
  {
    "objectID": "posts/noname/index.html#conclusion",
    "href": "posts/noname/index.html#conclusion",
    "title": "HW2 : Scrapying TMDB Website & Movie Recommandation",
    "section": "Conclusion",
    "text": "Conclusion\nIn this post, we looked through how we can apply scrapy to make a recommandation system. Web Scraping is a powerful tool to gather various data from the web."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BlogPic16B",
    "section": "",
    "text": "Final Group Project\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\nDonggyu Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHW5 : Text Classification : Spotting Fake News\n\n\n\n\n\n\nweek 8\n\n\nweek 9\n\n\nHW\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\nDonggyu Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHW5 : Text Classification : Spotting Fake News\n\n\n\n\n\n\nweek 8\n\n\nweek 9\n\n\nHW\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\nDonggyu Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHW3 : Message Bank Web Development Using Flask\n\n\n\n\n\n\nweek 4\n\n\nweek 5\n\n\nHW\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\nDonggyu Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHW2 : Scrapying TMDB Website & Movie Recommandation\n\n\n\n\n\n\nweek 3\n\n\nweek 4\n\n\nHW\n\n\n\n\n\n\n\n\n\nFeb 7, 2024\n\n\nDonggyu Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHW1 : Visualizing Climate Data using Query & Database\n\n\n\n\n\n\nweek 2\n\n\nweek 3\n\n\nHW\n\n\n\n\n\n\n\n\n\nJan 29, 2024\n\n\nDonggyu Kim\n\n\n\n\n\n\n\n\n\n\n\n\nHW0 Creating Post\n\n\n\n\n\n\nweek 1\n\n\nHW\n\n\n\n\n\n\n\n\n\nJan 22, 2024\n\n\nDonggyu Kim\n\n\n\n\n\n\nNo matching items"
  }
]